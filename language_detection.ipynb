{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8840b82a",
   "metadata": {},
   "source": [
    "**Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751ab3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "import os\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import permutations\n",
    "import collections\n",
    "import string\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748ec3d",
   "metadata": {},
   "source": [
    "**Extract dataset archive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e3dd919",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = tarfile.open('./europarl.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "021f81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "462c62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'German':'de',\n",
    "    'English': 'en',\n",
    "    'Spanish':'es',\n",
    "    'French':'fr',\n",
    "    'Hungarian':'hu',\n",
    "    'Romanian':'ro'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80798b80",
   "metadata": {},
   "source": [
    "**Convert txt to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "789197ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'txt'\n",
    "directories = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7417920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting txt to csv begun\n",
      "Converting de to csv begun\n",
      "Conversion done \n",
      "\n",
      "Converting en to csv begun\n",
      "Conversion done \n",
      "\n",
      "Converting es to csv begun\n",
      "Conversion done \n",
      "\n",
      "Converting fr to csv begun\n",
      "Conversion done \n",
      "\n",
      "Converting hu to csv begun\n",
      "Conversion done \n",
      "\n",
      "Converting ro to csv begun\n",
      "Conversion done \n",
      "\n",
      "--- 292.29198837280273 seconds ---\n",
      "Converting from txt to csv done\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Converting txt to csv begun')\n",
    "for lang in directories:\n",
    "    print('Converting '+lang+' to csv begun')\n",
    "    paths = path + '/' + lang\n",
    "    files = os.listdir(paths)\n",
    "    lang_type = [lang]\n",
    "    lang_type = open(lang+'.csv','w')\n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(paths+'/'+file, 'r', encoding = 'utf-8') as lines:\n",
    "                for line in lines:\n",
    "                    lang_type.write(line)\n",
    "        except UnicodeDecodeError:\n",
    "            with open(paths+'/'+file, 'r', encoding = 'unicode_escape') as lines:\n",
    "                for line in lines:\n",
    "                    lang_type.write(line)\n",
    "        except UnicodeEncodeError:\n",
    "            pass\n",
    "    print(\"Conversion done \\n\")\n",
    "                    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Converting from txt to csv done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d31739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty dataframe\n",
    "df = pd.DataFrame(columns = ['Sentences', 'Language_Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f0a17",
   "metadata": {},
   "source": [
    "**Concatenating all of the csv files + a bit of text formatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e391736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German de \n",
      "\n",
      "German Data loaded, Pre-processing begun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/2077097468.py:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data.loc[:, 'Sentences'] = data.loc[:, 'Sentences'].str.replace(r''+character,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 35.7468466758728 seconds ---\n",
      "Pre-processing of  German  finished \n",
      "\n",
      "English en \n",
      "\n",
      "English Data loaded, Pre-processing begun\n",
      "--- 36.2200562953949 seconds ---\n",
      "Pre-processing of  English  finished \n",
      "\n",
      "Spanish es \n",
      "\n",
      "Spanish Data loaded, Pre-processing begun\n",
      "--- 40.12695789337158 seconds ---\n",
      "Pre-processing of  Spanish  finished \n",
      "\n",
      "French fr \n",
      "\n",
      "French Data loaded, Pre-processing begun\n",
      "--- 42.54697823524475 seconds ---\n",
      "Pre-processing of  French  finished \n",
      "\n",
      "Hungarian hu \n",
      "\n",
      "Hungarian Data loaded, Pre-processing begun\n",
      "--- 6.016124725341797 seconds ---\n",
      "Pre-processing of  Hungarian  finished \n",
      "\n",
      "Romanian ro \n",
      "\n",
      "Romanian Data loaded, Pre-processing begun\n",
      "--- 5.480081558227539 seconds ---\n",
      "Pre-processing of  Romanian  finished \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in labels.keys():\n",
    "    print(label, labels[label],'\\n')\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #loading data for individual languages\n",
    "        data = pd.read_csv(labels[label] + '.csv', sep = 'delimiter', header = None,\n",
    "                            engine = 'python', index_col = False, encoding = 'latin-1')\n",
    "        data.columns = ['Sentences']\n",
    "        data = data[~data.Sentences.str.contains(\"<\")]\n",
    "        characters = ['1','2','3','4','5','6','7','8','9','0', '@',\"'\",'#','$','%',\n",
    "                    '&','/','(',')','\"','.',',','?','/','!','=',':',';']\n",
    "        \n",
    "        print(label, 'Data loaded, Pre-processing begun')\n",
    "        for character in characters:\n",
    "            data.loc[:, 'Sentences'] = data.loc[:, 'Sentences'].str.replace(r''+character, \n",
    "                                                                    \"\")\n",
    "        data['Language_Type'] = label\n",
    "        df = pd.concat([df, data], axis = 0, ignore_index = True)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print('Pre-processing of ',label,' finished \\n')\n",
    "        \n",
    "    except:\n",
    "        start_time = time.time()\n",
    "        data = pd.read_csv(labels[label]+'.csv', sep='delimiter', \n",
    "                                           header=None, error_bad_lines=False, \n",
    "                                           index_col = False)\n",
    "        data.columns = ['Sentences']\n",
    "        data = data[~data.Sentences.str.contains(\"<\")]\n",
    "        characters = ['1','2','3','4','5','6','7','8','9','0', '@',\"'\",'#','$','%',\n",
    "                    '&','/','(',')','\"','.',',','?','/','!','=',':',';']\n",
    "        print(label, 'Data loaded, Pre-processing begun (encoding error)')\n",
    "        \n",
    "        for character in characters:\n",
    "            data.loc[:, 'Sentences'] = data.loc[:, 'Sentences'].str.replace(r''+character, \n",
    "                                                                    \"\")\n",
    "        \n",
    "        data['Language_Type'] = label\n",
    "        df = pd.concat([df, data], axis = 0, ignore_index = True)\n",
    "        \n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print('Pre-processing of ',label,' finished \\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72ad09ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language</th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genehmigung des Protokolls der vorangegangenen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Das Protokoll der letzten Sitzung wurde verteilt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gibt es Einwände</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herr Präsident ich entspreche hiermit einer vo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erstens glaube ich daß der vom Vorsitzenden de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985471</th>\n",
       "      <td>Reluarea sesiunii</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985472</th>\n",
       "      <td>Transferuri de credite a se vedea procesul-verbal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985473</th>\n",
       "      <td>Depunerea documentelor a se vedea procesul-verbal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985474</th>\n",
       "      <td>Depunerea documentelor a se vedea procesul-verbal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985475</th>\n",
       "      <td>Trialogul privind proiectul de buget  dezbatere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1985476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language  \\\n",
       "0        Genehmigung des Protokolls der vorangegangenen...      NaN   \n",
       "1         Das Protokoll der letzten Sitzung wurde verteilt      NaN   \n",
       "2                                         Gibt es Einwände      NaN   \n",
       "3        Herr Präsident ich entspreche hiermit einer vo...      NaN   \n",
       "4        Erstens glaube ich daß der vom Vorsitzenden de...      NaN   \n",
       "...                                                    ...      ...   \n",
       "1985471                                  Reluarea sesiunii      NaN   \n",
       "1985472  Transferuri de credite a se vedea procesul-verbal      NaN   \n",
       "1985473  Depunerea documentelor a se vedea procesul-verbal      NaN   \n",
       "1985474  Depunerea documentelor a se vedea procesul-verbal      NaN   \n",
       "1985475    Trialogul privind proiectul de buget  dezbatere      NaN   \n",
       "\n",
       "        Language_Type  \n",
       "0              German  \n",
       "1              German  \n",
       "2              German  \n",
       "3              German  \n",
       "4              German  \n",
       "...               ...  \n",
       "1985471      Romanian  \n",
       "1985472      Romanian  \n",
       "1985473      Romanian  \n",
       "1985474      Romanian  \n",
       "1985475      Romanian  \n",
       "\n",
       "[1985476 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0c8464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['German', 'English', 'Spanish', 'French', 'Hungarian', 'Romanian'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Language_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "feedb6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Language'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f5ab2",
   "metadata": {},
   "source": [
    "**The dataset, which is going to be used in the upcoming steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0f81b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genehmigung des Protokolls der vorangegangenen...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Das Protokoll der letzten Sitzung wurde verteilt</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gibt es Einwände</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herr Präsident ich entspreche hiermit einer vo...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erstens glaube ich daß der vom Vorsitzenden de...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985471</th>\n",
       "      <td>Reluarea sesiunii</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985472</th>\n",
       "      <td>Transferuri de credite a se vedea procesul-verbal</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985473</th>\n",
       "      <td>Depunerea documentelor a se vedea procesul-verbal</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985474</th>\n",
       "      <td>Depunerea documentelor a se vedea procesul-verbal</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985475</th>\n",
       "      <td>Trialogul privind proiectul de buget  dezbatere</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1985476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language_Type\n",
       "0        Genehmigung des Protokolls der vorangegangenen...        German\n",
       "1         Das Protokoll der letzten Sitzung wurde verteilt        German\n",
       "2                                         Gibt es Einwände        German\n",
       "3        Herr Präsident ich entspreche hiermit einer vo...        German\n",
       "4        Erstens glaube ich daß der vom Vorsitzenden de...        German\n",
       "...                                                    ...           ...\n",
       "1985471                                  Reluarea sesiunii      Romanian\n",
       "1985472  Transferuri de credite a se vedea procesul-verbal      Romanian\n",
       "1985473  Depunerea documentelor a se vedea procesul-verbal      Romanian\n",
       "1985474  Depunerea documentelor a se vedea procesul-verbal      Romanian\n",
       "1985475    Trialogul privind proiectul de buget  dezbatere      Romanian\n",
       "\n",
       "[1985476 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5b6653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('eu_lang_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7477bfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "French       501840\n",
       "Spanish      495746\n",
       "German       492307\n",
       "English      489049\n",
       "Hungarian      5120\n",
       "Romanian       1414\n",
       "Name: Language_Type, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Language_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d33b3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates(subset=['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd9eb70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genehmigung des Protokolls der vorangegangenen...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Das Protokoll der letzten Sitzung wurde verteilt</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gibt es Einwände</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herr Präsident ich entspreche hiermit einer vo...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erstens glaube ich daß der vom Vorsitzenden de...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985462</th>\n",
       "      <td>Diverse</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985463</th>\n",
       "      <td>Summitul UE-Rusia</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985464</th>\n",
       "      <td>- În timpul votului</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985466</th>\n",
       "      <td>Madagascar dezbatere</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985475</th>\n",
       "      <td>Trialogul privind proiectul de buget  dezbatere</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858651 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language_Type\n",
       "0        Genehmigung des Protokolls der vorangegangenen...        German\n",
       "1         Das Protokoll der letzten Sitzung wurde verteilt        German\n",
       "2                                         Gibt es Einwände        German\n",
       "3        Herr Präsident ich entspreche hiermit einer vo...        German\n",
       "4        Erstens glaube ich daß der vom Vorsitzenden de...        German\n",
       "...                                                    ...           ...\n",
       "1985462                                            Diverse      Romanian\n",
       "1985463                                 Summitul UE-Rusia       Romanian\n",
       "1985464                                - În timpul votului      Romanian\n",
       "1985466                               Madagascar dezbatere      Romanian\n",
       "1985475    Trialogul privind proiectul de buget  dezbatere      Romanian\n",
       "\n",
       "[1858651 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52cd27",
   "metadata": {},
   "source": [
    "**Shuffle the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4b5b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = shuffle(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2fb96a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345508</th>\n",
       "      <td>El informe del Parlamento Europeo que ataca el...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051256</th>\n",
       "      <td>En segundo lugar desde la Unión Europea tambié...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407002</th>\n",
       "      <td>Abfalldeponien</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921683</th>\n",
       "      <td>Mr President Mr Böschs report on the independe...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35310</th>\n",
       "      <td>Wir sollten nicht so oberflächlich und willfäh...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479356</th>\n",
       "      <td>Was Herrn Langen und die vorgeschlagenen Änder...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515964</th>\n",
       "      <td>In particular additional measures are required...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538828</th>\n",
       "      <td>Enfin Mesdames et Messieurs les Députés je sui...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068786</th>\n",
       "      <td>Resumiendo sólo puedo reiterar una vez más que...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471883</th>\n",
       "      <td>Señora Presidenta ¿puedo explicarme Quiero que...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858651 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language_Type\n",
       "1345508  El informe del Parlamento Europeo que ataca el...       Spanish\n",
       "1051256  En segundo lugar desde la Unión Europea tambié...       Spanish\n",
       "407002                                      Abfalldeponien        German\n",
       "921683   Mr President Mr Böschs report on the independe...       English\n",
       "35310    Wir sollten nicht so oberflächlich und willfäh...        German\n",
       "...                                                    ...           ...\n",
       "479356   Was Herrn Langen und die vorgeschlagenen Änder...        German\n",
       "515964   In particular additional measures are required...       English\n",
       "1538828  Enfin Mesdames et Messieurs les Députés je sui...        French\n",
       "1068786  Resumiendo sólo puedo reiterar una vez más que...       Spanish\n",
       "1471883  Señora Presidenta ¿puedo explicarme Quiero que...       Spanish\n",
       "\n",
       "[1858651 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b78db",
   "metadata": {},
   "source": [
    "**Lower sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "920e314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Sentences'] = [s.lower() for s in df2['Sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c422346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>el informe del parlamento europeo que ataca el...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en segundo lugar desde la unión europea tambié...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abfalldeponien</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mr president mr böschs report on the independe...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wir sollten nicht so oberflächlich und willfäh...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858646</th>\n",
       "      <td>was herrn langen und die vorgeschlagenen änder...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858647</th>\n",
       "      <td>in particular additional measures are required...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858648</th>\n",
       "      <td>enfin mesdames et messieurs les députés je sui...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858649</th>\n",
       "      <td>resumiendo sólo puedo reiterar una vez más que...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858650</th>\n",
       "      <td>señora presidenta ¿puedo explicarme quiero que...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858651 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language_Type\n",
       "0        el informe del parlamento europeo que ataca el...       Spanish\n",
       "1        en segundo lugar desde la unión europea tambié...       Spanish\n",
       "2                                           abfalldeponien        German\n",
       "3        mr president mr böschs report on the independe...       English\n",
       "4        wir sollten nicht so oberflächlich und willfäh...        German\n",
       "...                                                    ...           ...\n",
       "1858646  was herrn langen und die vorgeschlagenen änder...        German\n",
       "1858647  in particular additional measures are required...       English\n",
       "1858648  enfin mesdames et messieurs les députés je sui...        French\n",
       "1858649  resumiendo sólo puedo reiterar una vez más que...       Spanish\n",
       "1858650  señora presidenta ¿puedo explicarme quiero que...       Spanish\n",
       "\n",
       "[1858651 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85b8407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48a2ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77227ed8",
   "metadata": {},
   "source": [
    "**Getting rid of stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9bccc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_en = set(stopwords.words('english')) \n",
    "stop_words_de = set(stopwords.words('german')) \n",
    "stop_words_es = set(stopwords.words('spanish')) \n",
    "stop_words_fr = set(stopwords.words('french')) \n",
    "stop_words_hu = set(stopwords.words('hungarian')) \n",
    "stop_words_ro = set(stopwords.words('romanian')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "65647098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence, stop_words):\n",
    "    tokens_no_stopwords = [w for w in word_tokenize(sentence) if not w in stop_words]\n",
    "    filtered_sentence = (\" \").join(tokens_no_stopwords)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5365cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_german = df2[df2['Language_Type'] == 'German']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d2036565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/1781704829.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_german['Sentences'] = [remove_stopwords(i, stop_words_de) for i in df_german['Sentences']]\n"
     ]
    }
   ],
   "source": [
    "df_german['Sentences'] = [remove_stopwords(i, stop_words_de) for i in df_german['Sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "809f7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hungarian = df2[df2['Language_Type'] == 'Hungarian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f482089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/2928460904.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_hungarian['Sentences'] = [remove_stopwords(i, stop_words_hu) for i in df_hungarian['Sentences']]\n"
     ]
    }
   ],
   "source": [
    "df_hungarian['Sentences'] = [remove_stopwords(i, stop_words_hu) for i in df_hungarian['Sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "929588cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_romanian = df2[df2['Language_Type'] == 'Romanian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "622b276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/2916831280.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_romanian['Sentences'] = [remove_stopwords(i, stop_words_ro) for i in df_romanian['Sentences']]\n"
     ]
    }
   ],
   "source": [
    "df_romanian['Sentences'] = [remove_stopwords(i, stop_words_ro) for i in df_romanian['Sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5a1aa60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df2[df2['Language_Type'] == 'English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "75945557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/2316609760.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english['Sentences'] = [remove_stopwords(i, stop_words_en) for i in df_english['Sentences']]\n"
     ]
    }
   ],
   "source": [
    "df_english['Sentences'] = [remove_stopwords(i, stop_words_en) for i in df_english['Sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e7202f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spanish = df2[df2['Language_Type'] == 'Spanish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c4551fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/3732133282.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_spanish['Sentences'] = [remove_stopwords(i, stop_words_es) for i in df_spanish['Sentences']]\n"
     ]
    }
   ],
   "source": [
    "df_spanish['Sentences'] = [remove_stopwords(i, stop_words_es) for i in df_spanish['Sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a0e18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_french = df2[df2['Language_Type'] == 'French']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f12b9da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/4049175846.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_french['Sentences'] = [remove_stopwords(i, stop_words_fr) for i in df_french['Sentences']]\n"
     ]
    }
   ],
   "source": [
    "df_french['Sentences'] = [remove_stopwords(i, stop_words_fr) for i in df_french['Sentences']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc493f",
   "metadata": {},
   "source": [
    "**Another concatenation of the clean dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0864b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.concat([df_english, df_german], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee08559b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr president mr böschs report independence ucl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr president going back colleagues mr pomés ru...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>course want europe varying speeds pioneering g...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>situation face standstill contract negotiation...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time seems certain information society develop...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919334</th>\n",
       "      <td>wissenschaft forschung - wer arbeiten wer mögl...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919335</th>\n",
       "      <td>diesbezüglich geht weißbuch europäische verkeh...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919336</th>\n",
       "      <td>zweites möchte nukleare sicherheit erwähnen ku...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919337</th>\n",
       "      <td>schwedischen vorsitzes rat vernünftigerweise e...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919338</th>\n",
       "      <td>herrn langen vorgeschlagenen änderungsanträge ...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>919339 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentences Language_Type\n",
       "0       mr president mr böschs report independence ucl...       English\n",
       "1       mr president going back colleagues mr pomés ru...       English\n",
       "2       course want europe varying speeds pioneering g...       English\n",
       "3       situation face standstill contract negotiation...       English\n",
       "4       time seems certain information society develop...       English\n",
       "...                                                   ...           ...\n",
       "919334  wissenschaft forschung - wer arbeiten wer mögl...        German\n",
       "919335  diesbezüglich geht weißbuch europäische verkeh...        German\n",
       "919336  zweites möchte nukleare sicherheit erwähnen ku...        German\n",
       "919337  schwedischen vorsitzes rat vernünftigerweise e...        German\n",
       "919338  herrn langen vorgeschlagenen änderungsanträge ...        German\n",
       "\n",
       "[919339 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d2f1bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.concat([df_3, df_french], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1e0b596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.concat([df_3, df_spanish], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f5d45f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.concat([df_3, df_hungarian], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0cee88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.concat([df_3, df_romanian], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d2e1bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2ad01b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_3.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "51b0141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = shuffle(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "11fd8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_3.reset_index()\n",
    "df_3 = df_3.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2f6e98",
   "metadata": {},
   "source": [
    "**New, tidy dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bc630153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last but not least möchte hochachtung kommissi...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr rehder first place tell referring resolutio...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frau kommissarin herr präsident werte kollegin...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sk quiero darle gracias proporcionarnos oportu...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pouvons effet sous-estimer fait bassin méditer...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858646</th>\n",
       "      <td>primero modo comisión trata asesoramiento cien...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858647</th>\n",
       "      <td>sozialdemokraten wünschen hilfe qualitätsverbe...</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858648</th>\n",
       "      <td>three weeks ago given honour chairing committe...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858649</th>\n",
       "      <td>asimismo decir programa presentado corresponde...</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858650</th>\n",
       "      <td>mr von wogau would like thank drafting splendi...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858651 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language_Type\n",
       "0        last but not least möchte hochachtung kommissi...        German\n",
       "1        mr rehder first place tell referring resolutio...       English\n",
       "2        frau kommissarin herr präsident werte kollegin...        German\n",
       "3        sk quiero darle gracias proporcionarnos oportu...       Spanish\n",
       "4        pouvons effet sous-estimer fait bassin méditer...        French\n",
       "...                                                    ...           ...\n",
       "1858646  primero modo comisión trata asesoramiento cien...       Spanish\n",
       "1858647  sozialdemokraten wünschen hilfe qualitätsverbe...        German\n",
       "1858648  three weeks ago given honour chairing committe...       English\n",
       "1858649  asimismo decir programa presentado corresponde...       Spanish\n",
       "1858650  mr von wogau would like thank drafting splendi...       English\n",
       "\n",
       "[1858651 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372eca2",
   "metadata": {},
   "source": [
    "**Saving the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0b7b62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv('important_dataset_lang.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bef17a",
   "metadata": {},
   "source": [
    "**Extracting features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "046da136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['word_count'] = df['Sentences'].apply(lambda x : len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dd11e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last but not least möchte hochachtung kommissi...</td>\n",
       "      <td>German</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr rehder first place tell referring resolutio...</td>\n",
       "      <td>English</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frau kommissarin herr präsident werte kollegin...</td>\n",
       "      <td>German</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sk quiero darle gracias proporcionarnos oportu...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pouvons effet sous-estimer fait bassin méditer...</td>\n",
       "      <td>French</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858646</th>\n",
       "      <td>primero modo comisión trata asesoramiento cien...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858647</th>\n",
       "      <td>sozialdemokraten wünschen hilfe qualitätsverbe...</td>\n",
       "      <td>German</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858648</th>\n",
       "      <td>three weeks ago given honour chairing committe...</td>\n",
       "      <td>English</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858649</th>\n",
       "      <td>asimismo decir programa presentado corresponde...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858650</th>\n",
       "      <td>mr von wogau would like thank drafting splendi...</td>\n",
       "      <td>English</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858651 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language_Type  \\\n",
       "0        last but not least möchte hochachtung kommissi...        German   \n",
       "1        mr rehder first place tell referring resolutio...       English   \n",
       "2        frau kommissarin herr präsident werte kollegin...        German   \n",
       "3        sk quiero darle gracias proporcionarnos oportu...       Spanish   \n",
       "4        pouvons effet sous-estimer fait bassin méditer...        French   \n",
       "...                                                    ...           ...   \n",
       "1858646  primero modo comisión trata asesoramiento cien...       Spanish   \n",
       "1858647  sozialdemokraten wünschen hilfe qualitätsverbe...        German   \n",
       "1858648  three weeks ago given honour chairing committe...       English   \n",
       "1858649  asimismo decir programa presentado corresponde...       Spanish   \n",
       "1858650  mr von wogau would like thank drafting splendi...       English   \n",
       "\n",
       "         word_count  \n",
       "0                 6  \n",
       "1                 7  \n",
       "2                 3  \n",
       "3                34  \n",
       "4                76  \n",
       "...             ...  \n",
       "1858646         155  \n",
       "1858647         108  \n",
       "1858648          64  \n",
       "1858649          75  \n",
       "1858650          66  \n",
       "\n",
       "[1858651 rows x 3 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6f3fa01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['character_count'] = df['Sentences'].apply(lambda x : len(x.replace(\" \",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1624df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['word_density'] = df_3['word_count'] / (df_3['character_count'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "12bc9be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Language_Type</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>num_double_consec_vowels</th>\n",
       "      <th>num_consec_vowels</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>num_special_vowels</th>\n",
       "      <th>vowel_density</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_repeated_words</th>\n",
       "      <th>words_vs_unique</th>\n",
       "      <th>num_any_special_character</th>\n",
       "      <th>num_double_consec_consonants</th>\n",
       "      <th>num_consonants</th>\n",
       "      <th>consonant_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last but not least möchte hochachtung kommissi...</td>\n",
       "      <td>German</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr rehder first place tell referring resolutio...</td>\n",
       "      <td>English</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>7.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frau kommissarin herr präsident werte kollegin...</td>\n",
       "      <td>German</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sk quiero darle gracias proporcionarnos oportu...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>34</td>\n",
       "      <td>212</td>\n",
       "      <td>0.159624</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>164</td>\n",
       "      <td>27</td>\n",
       "      <td>4.823529</td>\n",
       "      <td>144</td>\n",
       "      <td>18</td>\n",
       "      <td>4.235294</td>\n",
       "      <td>165</td>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "      <td>4.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pouvons effet sous-estimer fait bassin méditer...</td>\n",
       "      <td>French</td>\n",
       "      <td>76</td>\n",
       "      <td>468</td>\n",
       "      <td>0.162047</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858646</th>\n",
       "      <td>primero modo comisión trata asesoramiento cien...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>155</td>\n",
       "      <td>831</td>\n",
       "      <td>0.186298</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>0.522581</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>0.587097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858647</th>\n",
       "      <td>sozialdemokraten wünschen hilfe qualitätsverbe...</td>\n",
       "      <td>German</td>\n",
       "      <td>108</td>\n",
       "      <td>582</td>\n",
       "      <td>0.185249</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858648</th>\n",
       "      <td>three weeks ago given honour chairing committe...</td>\n",
       "      <td>English</td>\n",
       "      <td>64</td>\n",
       "      <td>310</td>\n",
       "      <td>0.205788</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>1.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858649</th>\n",
       "      <td>asimismo decir programa presentado corresponde...</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>75</td>\n",
       "      <td>393</td>\n",
       "      <td>0.190355</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858650</th>\n",
       "      <td>mr von wogau would like thank drafting splendi...</td>\n",
       "      <td>English</td>\n",
       "      <td>66</td>\n",
       "      <td>351</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858651 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentences Language_Type  \\\n",
       "0        last but not least möchte hochachtung kommissi...        German   \n",
       "1        mr rehder first place tell referring resolutio...       English   \n",
       "2        frau kommissarin herr präsident werte kollegin...        German   \n",
       "3        sk quiero darle gracias proporcionarnos oportu...       Spanish   \n",
       "4        pouvons effet sous-estimer fait bassin méditer...        French   \n",
       "...                                                    ...           ...   \n",
       "1858646  primero modo comisión trata asesoramiento cien...       Spanish   \n",
       "1858647  sozialdemokraten wünschen hilfe qualitätsverbe...        German   \n",
       "1858648  three weeks ago given honour chairing committe...       English   \n",
       "1858649  asimismo decir programa presentado corresponde...       Spanish   \n",
       "1858650  mr von wogau would like thank drafting splendi...       English   \n",
       "\n",
       "         word_count  character_count  word_density  num_double_consec_vowels  \\\n",
       "0                 6               49      0.120000                         1   \n",
       "1                 7               42      0.162791                         4   \n",
       "2                 3               14      0.200000                         0   \n",
       "3                34              212      0.159624                         2   \n",
       "4                76              468      0.162047                         0   \n",
       "...             ...              ...           ...                       ...   \n",
       "1858646         155              831      0.186298                         0   \n",
       "1858647         108              582      0.185249                         0   \n",
       "1858648          64              310      0.205788                         3   \n",
       "1858649          75              393      0.190355                         0   \n",
       "1858650          66              351      0.187500                         0   \n",
       "\n",
       "         num_consec_vowels  num_vowels  num_special_vowels  vowel_density  \\\n",
       "0                        6          39                   1       6.500000   \n",
       "1                       11          52                   0       7.428571   \n",
       "2                        9          28                   3       9.333333   \n",
       "3                       51         164                  27       4.823529   \n",
       "4                       16          32                   8       0.421053   \n",
       "...                    ...         ...                 ...            ...   \n",
       "1858646                 21          90                  13       0.580645   \n",
       "1858647                 20          52                   5       0.481481   \n",
       "1858648                 22          74                   0       1.156250   \n",
       "1858649                  8          43                   5       0.573333   \n",
       "1858650                  6          20                   0       0.303030   \n",
       "\n",
       "         num_unique_words  num_repeated_words  words_vs_unique  \\\n",
       "0                      39                   0         6.500000   \n",
       "1                      51                   1         7.285714   \n",
       "2                      26                   1         8.666667   \n",
       "3                     144                  18         4.235294   \n",
       "4                      30                   2         0.394737   \n",
       "...                   ...                 ...              ...   \n",
       "1858646                81                   9         0.522581   \n",
       "1858647                57                   1         0.527778   \n",
       "1858648                70                   4         1.093750   \n",
       "1858649                43                   3         0.573333   \n",
       "1858650                20                   1         0.303030   \n",
       "\n",
       "         num_any_special_character  num_double_consec_consonants  \\\n",
       "0                               39                             7   \n",
       "1                               53                            10   \n",
       "2                               28                             7   \n",
       "3                              165                             6   \n",
       "4                               32                             8   \n",
       "...                            ...                           ...   \n",
       "1858646                         91                             2   \n",
       "1858647                         58                             7   \n",
       "1858648                         74                            12   \n",
       "1858649                         46                             2   \n",
       "1858650                         21                             1   \n",
       "\n",
       "         num_consonants  consonant_density  \n",
       "0                    39           6.500000  \n",
       "1                    53           7.571429  \n",
       "2                    28           9.333333  \n",
       "3                   164           4.823529  \n",
       "4                    32           0.421053  \n",
       "...                 ...                ...  \n",
       "1858646              91           0.587097  \n",
       "1858647              56           0.518519  \n",
       "1858648              74           1.156250  \n",
       "1858649              43           0.573333  \n",
       "1858650              21           0.318182  \n",
       "\n",
       "[1858651 rows x 17 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9658a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = ['a','e','i','o','u']\n",
    "special_vowels = ['á','é','í','ó','ú','ü','ö']\n",
    "same_consecutive_vowels = ['aa','ee', 'ii', 'oo', 'uu'] \n",
    "consecutive_vowels = [''.join(p) for p in permutations(vowels,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1cb330fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['num_double_consec_vowels'] = df_3['Sentences'].apply(lambda x : sum([any(c_v in a for c_v in same_consecutive_vowels) for a in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "729fe315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_3['num_consec_vowels'] = df_3['Sentences'].apply(lambda x : sum([any(c_v in a for c_v in consecutive_vowels) for a in x.split()]))\n",
    "#df_3['num_vowels'] = df_3['Sentences'].apply(lambda x : sum([any(v in a for v in vowels) for a in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "612961d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['num_special_vowels'] = df_3['Sentences'].apply(lambda x : sum([any(v in a for v in special_vowels) for a in x.split()]))\n",
    "df_3['vowel_density'] = df_3['num_vowels'] / df_3['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f7f2d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['num_unique_words'] = df_3['Sentences'].apply(lambda x: len(set(w for w in x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0a006e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['num_repeated_words'] = df_3['Sentences'].apply(lambda x: len([w for w in collections.Counter(x.split()).values() if w > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5d42956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['words_vs_unique'] = df_3['num_unique_words'] / df_3['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c8da4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_list = list(alphabet_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d2cbe5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['num_any_special_character'] = df_3['Sentences'].apply(lambda x : sum([any(not spc in sp for spc in alphabet_list) for sp in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ee16c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "consonants = [item for item in alphabet_list if item not in vowels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3ebd669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consecutive_consonants = [''.join(p) for p in permutations(consonants,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c1c41fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_3['num_consec_consonants'] = df_3['Sentences'].apply(lambda x : sum([any(c_v in a for c_v in consecutive_consonants) for a in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6861d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_consecutive_consonants = [str(l) + str(l) for l in consonants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "38febe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['num_double_consec_consonants'] = df_3['Sentences'].apply(lambda x : sum([any(c_c in b for c_c in same_consecutive_consonants) for b in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f5247d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['num_consonants'] = df_3['Sentences'].apply(lambda x : sum([any(c in aa for c in consonants) for aa in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2e3ab58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['consonant_density'] = df_3['num_consonants'] / df_3['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c7b64a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1858651"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b7bacc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "75287583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1858651"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_3.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7f76926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_3.drop(['vowel_density', 'words_vs_unique', 'consonant_density'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ae009875",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df = df_3.groupby('Language_Type').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a817ece9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Language_Type</th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "      <th>German</th>\n",
       "      <th>Hungarian</th>\n",
       "      <th>Romanian</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>71.726823</td>\n",
       "      <td>71.603246</td>\n",
       "      <td>71.586164</td>\n",
       "      <td>71.638750</td>\n",
       "      <td>69.635849</td>\n",
       "      <td>71.626631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character_count</th>\n",
       "      <td>380.832341</td>\n",
       "      <td>380.209385</td>\n",
       "      <td>380.112526</td>\n",
       "      <td>379.587903</td>\n",
       "      <td>371.709434</td>\n",
       "      <td>380.433687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_density</th>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.187849</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>0.188608</td>\n",
       "      <td>0.187805</td>\n",
       "      <td>0.187832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_double_consec_vowels</th>\n",
       "      <td>1.310052</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>0.428013</td>\n",
       "      <td>0.037222</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>0.170674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consec_vowels</th>\n",
       "      <td>11.727756</td>\n",
       "      <td>19.645086</td>\n",
       "      <td>12.238664</td>\n",
       "      <td>0.755068</td>\n",
       "      <td>1.801887</td>\n",
       "      <td>10.599407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_vowels</th>\n",
       "      <td>37.256517</td>\n",
       "      <td>44.500277</td>\n",
       "      <td>35.284596</td>\n",
       "      <td>5.715852</td>\n",
       "      <td>4.560377</td>\n",
       "      <td>39.206592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_special_vowels</th>\n",
       "      <td>0.038221</td>\n",
       "      <td>8.781594</td>\n",
       "      <td>3.026262</td>\n",
       "      <td>4.301429</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>6.975626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_unique_words</th>\n",
       "      <td>33.773925</td>\n",
       "      <td>40.757981</td>\n",
       "      <td>33.159030</td>\n",
       "      <td>6.100698</td>\n",
       "      <td>4.707547</td>\n",
       "      <td>35.777955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_repeated_words</th>\n",
       "      <td>3.346745</td>\n",
       "      <td>3.653720</td>\n",
       "      <td>2.218763</td>\n",
       "      <td>0.121967</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>3.043442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_any_special_character</th>\n",
       "      <td>38.046421</td>\n",
       "      <td>45.337390</td>\n",
       "      <td>35.846855</td>\n",
       "      <td>6.238285</td>\n",
       "      <td>4.732075</td>\n",
       "      <td>39.614444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_double_consec_consonants</th>\n",
       "      <td>4.818683</td>\n",
       "      <td>7.772593</td>\n",
       "      <td>6.437806</td>\n",
       "      <td>0.786640</td>\n",
       "      <td>0.111321</td>\n",
       "      <td>1.244272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consonants</th>\n",
       "      <td>37.643853</td>\n",
       "      <td>44.425396</td>\n",
       "      <td>35.437323</td>\n",
       "      <td>6.009970</td>\n",
       "      <td>4.564151</td>\n",
       "      <td>39.271575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Language_Type                    English      French      German   Hungarian  \\\n",
       "word_count                     71.726823   71.603246   71.586164   71.638750   \n",
       "character_count               380.832341  380.209385  380.112526  379.587903   \n",
       "word_density                    0.187900    0.187849    0.187893    0.188608   \n",
       "num_double_consec_vowels        1.310052    0.164084    0.428013    0.037222   \n",
       "num_consec_vowels              11.727756   19.645086   12.238664    0.755068   \n",
       "num_vowels                     37.256517   44.500277   35.284596    5.715852   \n",
       "num_special_vowels              0.038221    8.781594    3.026262    4.301429   \n",
       "num_unique_words               33.773925   40.757981   33.159030    6.100698   \n",
       "num_repeated_words              3.346745    3.653720    2.218763    0.121967   \n",
       "num_any_special_character      38.046421   45.337390   35.846855    6.238285   \n",
       "num_double_consec_consonants    4.818683    7.772593    6.437806    0.786640   \n",
       "num_consonants                 37.643853   44.425396   35.437323    6.009970   \n",
       "\n",
       "Language_Type                   Romanian     Spanish  \n",
       "word_count                     69.635849   71.626631  \n",
       "character_count               371.709434  380.433687  \n",
       "word_density                    0.187805    0.187832  \n",
       "num_double_consec_vowels        0.198113    0.170674  \n",
       "num_consec_vowels               1.801887   10.599407  \n",
       "num_vowels                      4.560377   39.206592  \n",
       "num_special_vowels              0.013208    6.975626  \n",
       "num_unique_words                4.707547   35.777955  \n",
       "num_repeated_words              0.022642    3.043442  \n",
       "num_any_special_character       4.732075   39.614444  \n",
       "num_double_consec_consonants    0.111321    1.244272  \n",
       "num_consonants                  4.564151   39.271575  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d80bc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.corr(method ='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "04bf3476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>num_double_consec_vowels</th>\n",
       "      <th>num_consec_vowels</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>num_special_vowels</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_repeated_words</th>\n",
       "      <th>num_any_special_character</th>\n",
       "      <th>num_double_consec_consonants</th>\n",
       "      <th>num_consonants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980592</td>\n",
       "      <td>0.131036</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>-0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character_count</th>\n",
       "      <td>0.980592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>-0.000955</td>\n",
       "      <td>-0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_density</th>\n",
       "      <td>0.131036</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>-0.000686</td>\n",
       "      <td>-0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_double_consec_vowels</th>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164866</td>\n",
       "      <td>0.251930</td>\n",
       "      <td>-0.185279</td>\n",
       "      <td>0.239247</td>\n",
       "      <td>0.257866</td>\n",
       "      <td>0.254152</td>\n",
       "      <td>0.187310</td>\n",
       "      <td>0.255460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consec_vowels</th>\n",
       "      <td>-0.001054</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.164866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888362</td>\n",
       "      <td>0.620745</td>\n",
       "      <td>0.882603</td>\n",
       "      <td>0.738713</td>\n",
       "      <td>0.888474</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>0.886251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_vowels</th>\n",
       "      <td>-0.000681</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>0.251930</td>\n",
       "      <td>0.888362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621474</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>0.998893</td>\n",
       "      <td>0.651577</td>\n",
       "      <td>0.999273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_special_vowels</th>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.185279</td>\n",
       "      <td>0.620745</td>\n",
       "      <td>0.621474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621682</td>\n",
       "      <td>0.490395</td>\n",
       "      <td>0.619104</td>\n",
       "      <td>0.354267</td>\n",
       "      <td>0.616442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_unique_words</th>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>0.239247</td>\n",
       "      <td>0.882603</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.621682</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767794</td>\n",
       "      <td>0.989540</td>\n",
       "      <td>0.655117</td>\n",
       "      <td>0.989642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_repeated_words</th>\n",
       "      <td>-0.000690</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.257866</td>\n",
       "      <td>0.738713</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>0.490395</td>\n",
       "      <td>0.767794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842471</td>\n",
       "      <td>0.529926</td>\n",
       "      <td>0.839235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_any_special_character</th>\n",
       "      <td>-0.000623</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>0.254152</td>\n",
       "      <td>0.888474</td>\n",
       "      <td>0.998893</td>\n",
       "      <td>0.619104</td>\n",
       "      <td>0.989540</td>\n",
       "      <td>0.842471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.654699</td>\n",
       "      <td>0.999165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_double_consec_consonants</th>\n",
       "      <td>-0.001018</td>\n",
       "      <td>-0.000955</td>\n",
       "      <td>-0.000686</td>\n",
       "      <td>0.187310</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>0.651577</td>\n",
       "      <td>0.354267</td>\n",
       "      <td>0.655117</td>\n",
       "      <td>0.529926</td>\n",
       "      <td>0.654699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consonants</th>\n",
       "      <td>-0.000665</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>0.255460</td>\n",
       "      <td>0.886251</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>0.616442</td>\n",
       "      <td>0.989642</td>\n",
       "      <td>0.839235</td>\n",
       "      <td>0.999165</td>\n",
       "      <td>0.651367</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              word_count  character_count  word_density  \\\n",
       "word_count                      1.000000         0.980592      0.131036   \n",
       "character_count                 0.980592         1.000000     -0.002371   \n",
       "word_density                    0.131036        -0.002371      1.000000   \n",
       "num_double_consec_vowels        0.000559         0.000489      0.000046   \n",
       "num_consec_vowels              -0.001054        -0.000996     -0.000604   \n",
       "num_vowels                     -0.000681        -0.000602     -0.000485   \n",
       "num_special_vowels             -0.000978        -0.000900     -0.000592   \n",
       "num_unique_words               -0.000591        -0.000514     -0.000527   \n",
       "num_repeated_words             -0.000690        -0.000638      0.000273   \n",
       "num_any_special_character      -0.000623        -0.000548     -0.000408   \n",
       "num_double_consec_consonants   -0.001018        -0.000955     -0.000686   \n",
       "num_consonants                 -0.000665        -0.000592     -0.000435   \n",
       "\n",
       "                              num_double_consec_vowels  num_consec_vowels  \\\n",
       "word_count                                    0.000559          -0.001054   \n",
       "character_count                               0.000489          -0.000996   \n",
       "word_density                                  0.000046          -0.000604   \n",
       "num_double_consec_vowels                      1.000000           0.164866   \n",
       "num_consec_vowels                             0.164866           1.000000   \n",
       "num_vowels                                    0.251930           0.888362   \n",
       "num_special_vowels                           -0.185279           0.620745   \n",
       "num_unique_words                              0.239247           0.882603   \n",
       "num_repeated_words                            0.257866           0.738713   \n",
       "num_any_special_character                     0.254152           0.888474   \n",
       "num_double_consec_consonants                  0.187310           0.718354   \n",
       "num_consonants                                0.255460           0.886251   \n",
       "\n",
       "                              num_vowels  num_special_vowels  \\\n",
       "word_count                     -0.000681           -0.000978   \n",
       "character_count                -0.000602           -0.000900   \n",
       "word_density                   -0.000485           -0.000592   \n",
       "num_double_consec_vowels        0.251930           -0.185279   \n",
       "num_consec_vowels               0.888362            0.620745   \n",
       "num_vowels                      1.000000            0.621474   \n",
       "num_special_vowels              0.621474            1.000000   \n",
       "num_unique_words                0.989857            0.621682   \n",
       "num_repeated_words              0.838428            0.490395   \n",
       "num_any_special_character       0.998893            0.619104   \n",
       "num_double_consec_consonants    0.651577            0.354267   \n",
       "num_consonants                  0.999273            0.616442   \n",
       "\n",
       "                              num_unique_words  num_repeated_words  \\\n",
       "word_count                           -0.000591           -0.000690   \n",
       "character_count                      -0.000514           -0.000638   \n",
       "word_density                         -0.000527            0.000273   \n",
       "num_double_consec_vowels              0.239247            0.257866   \n",
       "num_consec_vowels                     0.882603            0.738713   \n",
       "num_vowels                            0.989857            0.838428   \n",
       "num_special_vowels                    0.621682            0.490395   \n",
       "num_unique_words                      1.000000            0.767794   \n",
       "num_repeated_words                    0.767794            1.000000   \n",
       "num_any_special_character             0.989540            0.842471   \n",
       "num_double_consec_consonants          0.655117            0.529926   \n",
       "num_consonants                        0.989642            0.839235   \n",
       "\n",
       "                              num_any_special_character  \\\n",
       "word_count                                    -0.000623   \n",
       "character_count                               -0.000548   \n",
       "word_density                                  -0.000408   \n",
       "num_double_consec_vowels                       0.254152   \n",
       "num_consec_vowels                              0.888474   \n",
       "num_vowels                                     0.998893   \n",
       "num_special_vowels                             0.619104   \n",
       "num_unique_words                               0.989540   \n",
       "num_repeated_words                             0.842471   \n",
       "num_any_special_character                      1.000000   \n",
       "num_double_consec_consonants                   0.654699   \n",
       "num_consonants                                 0.999165   \n",
       "\n",
       "                              num_double_consec_consonants  num_consonants  \n",
       "word_count                                       -0.001018       -0.000665  \n",
       "character_count                                  -0.000955       -0.000592  \n",
       "word_density                                     -0.000686       -0.000435  \n",
       "num_double_consec_vowels                          0.187310        0.255460  \n",
       "num_consec_vowels                                 0.718354        0.886251  \n",
       "num_vowels                                        0.651577        0.999273  \n",
       "num_special_vowels                                0.354267        0.616442  \n",
       "num_unique_words                                  0.655117        0.989642  \n",
       "num_repeated_words                                0.529926        0.839235  \n",
       "num_any_special_character                         0.654699        0.999165  \n",
       "num_double_consec_consonants                      1.000000        0.651367  \n",
       "num_consonants                                    0.651367        1.000000  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab098e",
   "metadata": {},
   "source": [
    "**Train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0a31d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into features and target variable\n",
    "feature_cols = list(df_3.columns)[2:]\n",
    "X = df_3[feature_cols] # Features\n",
    "y = df_3[['Language_Type']] # Target variable\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% train and 20% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945e26a",
   "metadata": {},
   "source": [
    "**Reduce correlation among features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2ada6d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Principal Components = 6\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "# Transform both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Make an instance of the model to retain 95% of the variance within the old features.\n",
    "pca = PCA(.95)\n",
    "pca.fit(X_train)\n",
    "w\n",
    "print('Number of Principal Components = '+str(pca.n_components_))\n",
    "# Number of Principal Components = 13\n",
    "\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f4c41",
   "metadata": {},
   "source": [
    "**Model 1: Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d53bab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier() # Create Decision Tree classifer object\n",
    "dt_clf = dt_clf.fit(X_train,y_train) # Fit/Train Decision Tree Classifer on training set\n",
    "\n",
    "# Save model to file in the current working directory so that it can be imported and used.\n",
    "# I use the pickle library to save the parameters of the trained model\n",
    "pkl_file = \"decision_tree_model.pkl\"\n",
    "with open(pkl_file, 'wb') as file:\n",
    "    pickle.dump(dt_clf, file)\n",
    "\n",
    "# Load previously trained model from pickle file\n",
    "with open(pkl_file, 'rb') as file:\n",
    "    dt_clf = pickle.load(file)\n",
    "\n",
    "dt_clf # parameters of the Decision Tree model are shown below and can be further optimized to improve model performance\n",
    "\n",
    "y_pred = dt_clf.predict(X_test) #Predict the response for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2814edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1495689</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199606</th>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482952</th>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444374</th>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593883</th>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534297</th>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664544</th>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247132</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006105</th>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905512</th>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371731 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Language_Type\n",
       "1495689        French\n",
       "199606        Spanish\n",
       "1482952        German\n",
       "1444374        German\n",
       "593883         German\n",
       "...               ...\n",
       "1534297       English\n",
       "664544         German\n",
       "1247132        French\n",
       "1006105        French\n",
       "905512        Spanish\n",
       "\n",
       "[371731 rows x 1 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5c08dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_dt = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2770631",
   "metadata": {},
   "source": [
    "**Decision Tree accuracy score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c9009662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733872074161154"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a34097",
   "metadata": {},
   "source": [
    "**Model 2: Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "069ddb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DOCTOR~1\\AppData\\Local\\Temp/ipykernel_13576/1535180173.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_clf = rf_clf.fit(X_train,y_train) # Fit/Train Random Forest Classifer on training set\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100) # Create Random Forest classifer object\n",
    "rf_clf = rf_clf.fit(X_train,y_train) # Fit/Train Random Forest Classifer on training set\n",
    "\n",
    "# Save model to file in the current working directory so that it can be imported and used.\n",
    "pkl_file = \"random_forest_model.pkl\"\n",
    "with open(pkl_file, 'wb') as file:\n",
    "    pickle.dump(rf_clf, file)\n",
    "\n",
    "# Load previously trained model from pickle file\n",
    "with open(pkl_file, 'rb') as file:\n",
    "    rf_clf = pickle.load(file)\n",
    "rf_clf\n",
    "\n",
    "y_pred_random_forest = rf_clf.predict(X_test) #Predict the response for test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd15a0b",
   "metadata": {},
   "source": [
    "**Random Forest Accuracy Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "16494655",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_rf = accuracy_score(y_test, y_pred_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c1218df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275688602779967"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f2483",
   "metadata": {},
   "source": [
    "**Model 3: Gradient Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "350577a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Doctorate-T-PC\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=1)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Save model to file in the current working directory so that it can be imported and used.\n",
    "# I use the pickle library to save the parameters of the trained model\n",
    "pkl_file = \"gradient_boost_model.pkl\"\n",
    "with open(pkl_file, 'wb') as file:\n",
    "    pickle.dump(gb_clf, file)\n",
    "\n",
    "# Load previously trained model from pickle file\n",
    "with open(pkl_file, 'rb') as file:\n",
    "    gb_clf = pickle.load(file)\n",
    "\n",
    "gb_clf # parameters of the Gradient Boost model are shown below\n",
    "\n",
    "y_pred_gb = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f33bbf",
   "metadata": {},
   "source": [
    "**Gradient Boost Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b1299a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_gb = accuracy_score(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "465ffa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6211857499105536"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b6c52",
   "metadata": {},
   "source": [
    "**Example no. 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ac54220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"come on man lets get outta here, we need to go\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b37c6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataframe = pd.DataFrame(text, columns = ['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5e843ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>come on man lets get outta here, we need to go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Sentences\n",
       "0  come on man lets get outta here, we need to go"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689c00d",
   "metadata": {},
   "source": [
    "**Function for feature extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8d58e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(dataframe):\n",
    "    vowels = ['a','e','i','o','u']\n",
    "    special_vowels = ['á','é','í','ó','ú','ü','ö']\n",
    "    same_consecutive_vowels = ['aa','ee', 'ii', 'oo', 'uu'] \n",
    "    consecutive_vowels = [''.join(p) for p in permutations(vowels,2)]\n",
    "    \n",
    "    dataframe['word_count'] = dataframe['Sentences'].apply(lambda x : len(x.split()))\n",
    "    dataframe['character_count'] = dataframe['Sentences'].apply(lambda x : len(x.replace(\" \",\"\")))\n",
    "    dataframe['word_density'] = dataframe['word_count'] / (dataframe['character_count'] + 1)\n",
    "    \n",
    "    dataframe['num_double_consec_vowels'] = dataframe['Sentences'].apply(lambda x : sum([any(c_v in a for c_v in same_consecutive_vowels) for a in x.split()]))\n",
    "    dataframe['num_consec_vowels'] = dataframe['Sentences'].apply(lambda x : sum([any(c_v in a for c_v in consecutive_vowels) for a in x.split()]))\n",
    "    dataframe['num_vowels'] = dataframe['Sentences'].apply(lambda x : sum([any(v in a for v in vowels) for a in x.split()]))\n",
    "    dataframe['num_special_vowels'] = dataframe['Sentences'].apply(lambda x : sum([any(v in a for v in special_vowels) for a in x.split()]))\n",
    "\n",
    "    dataframe['num_unique_words'] = dataframe['Sentences'].apply(lambda x: len(set(w for w in x.split())))\n",
    "    dataframe['num_repeated_words'] = dataframe['Sentences'].apply(lambda x: len([w for w in collections.Counter(x.split()).values() if w > 1]))\n",
    "    \n",
    "    alphabet_string = string.ascii_lowercase\n",
    "    alphabet_list = list(alphabet_string)\n",
    "    \n",
    "    dataframe['num_any_special_character'] = dataframe['Sentences'].apply(lambda x : sum([any(not spc in sp for spc in alphabet_list) for sp in x.split()]))\n",
    "    \n",
    "    consonants = [item for item in alphabet_list if item not in vowels]\n",
    "    same_consecutive_consonants = [str(l) + str(l) for l in consonants]\n",
    "    \n",
    "    dataframe['num_double_consec_consonants'] = dataframe['Sentences'].apply(lambda x : sum([any(c_c in b for c_c in same_consecutive_consonants) for b in x.split()]))\n",
    "    dataframe['num_consonants'] = dataframe['Sentences'].apply(lambda x : sum([any(c in aa for c in consonants) for aa in x.split()]))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "59f68f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_dataframe = features(text_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8de8ee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>language</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>num_double_consec_vowels</th>\n",
       "      <th>num_consec_vowels</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>num_special_vowels</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_repeated_words</th>\n",
       "      <th>num_any_special_character</th>\n",
       "      <th>num_double_consec_consonants</th>\n",
       "      <th>num_consonants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>come on man lets get outta here, we need to go</td>\n",
       "      <td>english</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Sentences language  word_count  \\\n",
       "0  come on man lets get outta here, we need to go  english          11   \n",
       "\n",
       "   character_count  word_density  num_double_consec_vowels  num_consec_vowels  \\\n",
       "0               36      0.297297                         1                  1   \n",
       "\n",
       "   num_vowels  num_special_vowels  num_unique_words  num_repeated_words  \\\n",
       "0          11                   0                11                   0   \n",
       "\n",
       "   num_any_special_character  num_double_consec_consonants  num_consonants  \n",
       "0                         11                             1              11  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6e98765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_dataframe = new_text_dataframe.drop(['language'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "b0ab11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_dataframe.insert(1, 'language', 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "938c8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_ex = list(new_text_dataframe.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b140cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex = new_text_dataframe[feature_cols_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "39d9b85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>num_double_consec_vowels</th>\n",
       "      <th>num_consec_vowels</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>num_special_vowels</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_repeated_words</th>\n",
       "      <th>num_any_special_character</th>\n",
       "      <th>num_double_consec_consonants</th>\n",
       "      <th>num_consonants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  character_count  word_density  num_double_consec_vowels  \\\n",
       "0          11               36      0.297297                         1   \n",
       "\n",
       "   num_consec_vowels  num_vowels  num_special_vowels  num_unique_words  \\\n",
       "0                  1          11                   0                11   \n",
       "\n",
       "   num_repeated_words  num_any_special_character  \\\n",
       "0                   0                         11   \n",
       "\n",
       "   num_double_consec_consonants  num_consonants  \n",
       "0                             1              11  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "87dfb311",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex = scaler.transform(X_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9b46705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex = pca.transform(X_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "fc17b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ex = dt_clf.predict(X_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53090e68",
   "metadata": {},
   "source": [
    "**Prediction for example no. 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "98952b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English'], dtype=object)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e4f159",
   "metadata": {},
   "source": [
    "**Example no. 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f4b2f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_spanish = [\"ola dios mio que estas haciendo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "bee67f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataframe_es = pd.DataFrame(text_spanish, columns = ['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "68ff8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_dataframe_es = features(text_dataframe_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "331859d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_dataframe_es.insert(1, 'language', 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ace6deee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>language</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>num_double_consec_vowels</th>\n",
       "      <th>num_consec_vowels</th>\n",
       "      <th>num_vowels</th>\n",
       "      <th>num_special_vowels</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_repeated_words</th>\n",
       "      <th>num_any_special_character</th>\n",
       "      <th>num_double_consec_consonants</th>\n",
       "      <th>num_consonants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ola dios mio que estas haciendo</td>\n",
       "      <td>english</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Sentences language  word_count  character_count  \\\n",
       "0  ola dios mio que estas haciendo  english           6               26   \n",
       "\n",
       "   word_density  num_double_consec_vowels  num_consec_vowels  num_vowels  \\\n",
       "0      0.222222                         0                  4           6   \n",
       "\n",
       "   num_special_vowels  num_unique_words  num_repeated_words  \\\n",
       "0                   0                 6                   0   \n",
       "\n",
       "   num_any_special_character  num_double_consec_consonants  num_consonants  \n",
       "0                          6                             0               6  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text_dataframe_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "09899c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_ex_es = list(new_text_dataframe_es.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "211d419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex_es = new_text_dataframe_es[feature_cols_ex_es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1894ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex_es = scaler.transform(X_ex_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "5bb43b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex_es = pca.transform(X_ex_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9f7c8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ex_es = dt_clf.predict(X_ex_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe4e81",
   "metadata": {},
   "source": [
    "**Prediction for example no. 2 with Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "2ec5980c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English'], dtype=object)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ex_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "051a57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_random_forest_es = rf_clf.predict(X_ex_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d436e",
   "metadata": {},
   "source": [
    "**Prediction for example no. 2 with Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "446844eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English'], dtype=object)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_random_forest_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "cd0d1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_dataframe_es = new_text_dataframe_es.drop(['language'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b09383e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_dataframe_es.insert(1, 'language', 'spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "ad09484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb_es = gb_clf.predict(X_ex_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ce1535",
   "metadata": {},
   "source": [
    "**Prediction for example no. 2 with Gradient Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "2d8e3cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Romanian'], dtype=object)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gb_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a7e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
